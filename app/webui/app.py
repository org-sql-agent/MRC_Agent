import streamlit as st
from openai_env import OPENAI_MODEL, SD_API, client
from openai_function import TOOLS , SYSTEM_PROMPT
from tools import  img_to_data_uri, call_sd_txt2img, call_sd_img2img
import json, io, base64
import requests


# ========= Streamlit UI =========
st.set_page_config(page_title="SD + LoRA + OpenAI Orchestrator", layout="centered")
st.title("ğŸ¨ SD(+LoRA) Ã— OpenAI LLM Orchestrator")
st.caption("è¼¸å…¥æ–‡å­—ï¼Œæˆ–åŒæ™‚ä¸Šå‚³åƒè€ƒåœ–ã€‚LLM è‡ªå‹•é¸ txt2img / img2imgï¼Œä¸¦ä¸‹ç™¼æ­£ç¢ºåƒæ•¸ã€‚")

with st.form("gen"):
    user_text = st.text_area("ä½ çš„éœ€æ±‚ï¼ˆprompt æŒ‡ä»¤æˆ–è‡ªç„¶èªè¨€éƒ½å¯ï¼‰", height=120)
    uploaded = st.file_uploader("å¯é¸ï¼šä¸Šå‚³ä¸€å¼µåœ–ç‰‡ï¼ˆimg2img æœƒä½¿ç”¨ï¼‰", type=["png", "jpg", "jpeg", "webp"])
    col1, col2 = st.columns(2)
    with col1:
        temperature = 1 # st.slider("LLM æº«åº¦ï¼ˆè¶Šä½è¶Šä¿å®ˆï¼‰", 0.0, 1.0, 0.2, 0.05)
    with col2:
        dry_run = st.checkbox("åªçœ‹ LLM ç”¢ç”Ÿçš„ JSONï¼ˆä¸çœŸçš„ç”Ÿåœ–ï¼‰", value=False)
    submitted = st.form_submit_button("é€å‡º")

if submitted:
    if not user_text and not uploaded:
        st.warning("è«‹è‡³å°‘è¼¸å…¥æ–‡å­—æˆ–ä¸Šå‚³åœ–ç‰‡ã€‚")
        st.stop()

    # æº–å‚™ user è¨Šæ¯ï¼ˆå«åœ–åƒ Data URLï¼Œä¾› LLM ç†è§£ï¼‰
    uploaded_b64 = None
    user_content = []
    if user_text:
        user_content.append({"type": "text", "text": user_text})
    if uploaded:
        uploaded_b64 = img_to_data_uri(uploaded)
        # è®“ LLM çœ‹åˆ°åœ–ç‰‡ï¼ˆç”¨ visionï¼‰
        user_content.append({"type": "image_url", "image_url": {"url": uploaded_b64}})

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": user_content
        },
        # é¡å¤–æç¤º LLMï¼šç›®å‰æ˜¯å¦æœ‰ä¸Šå‚³åœ–ï¼ˆå¹«åŠ©è·¯ç”±åˆ¤æ–·ï¼‰
        {"role": "system", "content": f"ä½¿ç”¨è€…ç›®å‰{'æœ‰' if uploaded_b64 else 'æ²’æœ‰'}ä¸Šå‚³åœ–ç‰‡ã€‚"}
    ]

    # ç¬¬ä¸€æ¬¡ï¼šè«‹ LLM æ±ºå®šæ˜¯å¦è¦å‘¼å«å·¥å…·èˆ‡å¡«åƒæ•¸
    resp = client.chat.completions.create(
        model=OPENAI_MODEL,
        temperature=temperature,
        messages=messages,
        tools=TOOLS,
        tool_choice="auto",
    )

    msg = resp.choices[0].message
    tool_calls = msg.tool_calls or []

    if not tool_calls:
        st.error("æ¨¡å‹æ²’æœ‰å‘¼å«å·¥å…·ã€‚å¯èƒ½æ˜¯è¼¸å…¥ä¸è¶³æˆ–è¦å‰‡é™åˆ¶ã€‚")
        st.json({"llm_reply": msg})
        st.stop()

    # ç›®å‰è¨­è¨ˆï¼šåªè™•ç†ç¬¬ä¸€å€‹å·¥å…·å‘¼å«ï¼ˆå¤šå·¥å…·ä¹Ÿèƒ½æ“´å……æˆè¿´åœˆï¼‰
    tc = tool_calls[0]
    fn_name = tc.function.name
    fn_args = json.loads(tc.function.arguments or "{}")

    st.subheader("ğŸ§  LLM æ±ºç­–ï¼ˆå·¥å…·èˆ‡åƒæ•¸ï¼‰")
    st.code(json.dumps({"tool": fn_name, "args": fn_args}, ensure_ascii=False, indent=2), language="json")

    if dry_run:
        st.info("Dry runï¼šæœªå‘¼å« SD å¾Œç«¯ã€‚")
        st.stop()

    try:
        if fn_name == "txt2img":
            result = call_sd_txt2img(fn_args)
        elif fn_name == "img2img":
            result = call_sd_img2img(fn_args, uploaded_b64)
        else:
            raise ValueError(f"æœªçŸ¥å·¥å…·ï¼š{fn_name}")
    except requests.HTTPError as e:
        st.error(f"SD å¾Œç«¯éŒ¯èª¤ï¼š{e}\n{e.response.text if e.response is not None else ''}")
        st.stop()
    except Exception as e:
        st.error(f"å·¥å…·åŸ·è¡Œå¤±æ•—ï¼š{e}")
        st.stop()

    # é¡¯ç¤ºç”Ÿæˆåœ–ç‰‡
    img_b64 = result["image_base64"].split(",", 1)[1]
    st.image(io.BytesIO(base64.b64decode(img_b64)), caption=f"seed={result['seed']}, size={result['width']}x{result['height']}")
    with st.expander("ç”Ÿæˆçš„ä¸­ç¹¼è³‡è¨Š"):
        st.json(result, expanded=False)

    # ï¼ˆå¯é¸ï¼‰ç¬¬äºŒæ¬¡ï¼šæŠŠå·¥å…·è¼¸å‡ºå›é¥‹çµ¦ LLMï¼Œç”¢ç”Ÿä¸€å¥è‡ªç„¶èªè¨€èªªæ˜
    follow_messages = messages + [
        msg,  # åŸæœ¬æ¨¡å‹è¨Šæ¯ï¼ˆå« tool_callï¼‰
        {
            "role": "tool",
            "tool_call_id": tc.id,
            "name": fn_name,
            "content": json.dumps({k: result[k] for k in ("seed", "width", "height", "steps", "guidance_scale", "applied_loras")}, ensure_ascii=False),
        },
        {"role": "user", "content": "è«‹ç”¨ä¸€å¥è©±å¹«æˆ‘ç¸½çµé€™æ¬¡çš„ç”Ÿæˆé‡é»ã€‚"}
    ]
    explain = client.chat.completions.create(
        model=OPENAI_MODEL, temperature=1, messages=follow_messages
    )
    st.caption("ğŸ“ " + (explain.choices[0].message.content or "").strip())
